[{"content":" Introduction I\u0026rsquo;ve been using an Allwinner S3 SoC for experiments with the FLIR Boson. The description from the website sums the device up nicely:\nS3 is a high cost-effective video encoding processor jointly developed by Zhuhai Allwinner Technology Co., Ltd. (\u0026ldquo;Allwinner\u0026rdquo;) and Sochip Technology Co., Ltd. (\u0026ldquo;Sochip\u0026rdquo;). Its built-in single-core ARM Cortex-A7 runs at 1.2GHz with 1Gbit DRAM (DDR3) , supporting numerous peripheral devices. The Chip package is 234 balls FBGA package, size 11mm x 11mm , suitable for various types of product development. \u0026mdash; http://www.sochip.com.cn/s3/index.php?title=What_is_S3_%3F\nWhat was appealing to me for use with the Boson thermal camera is the compact BGA package, the internal DRAM, and embedded ethernet 100 Mbit PHY. Interestingly the CPU used inside is the same as the V3/V3s/S3, there is mainline kernel and uboot support. This is good because I\u0026rsquo;m very much an embedded Linux beginner.\nAfter following the reference design provided by SOChip, along with some other great OSHW projects:\nhttps://github.com/Jana-Marie/OtterCam-s3 https://github.com/Ottercast/OtterCastAudioV2 https://github.com/OLIMEX/S3-OLinuXino I had a custom board designed. After some quick assembly I had a board that powered up. Soon after that with a custom buildroot project, and had linux 5.18 booted on the board. 🙌\nH264 Encoder After some initial testing with libopenh264 with ffmpeg the performance is not great. Achieving only a few fps encoding an incoming USB UVC stream into h264. Not a dealbreaker for this project.\nThe S3 contains a hardware encoding block that claims performance of 120FPS, this block is the same across many Allwinner parts. One such part is the H3. Unfortunately it\u0026rsquo;s not documented by Allwinner. If you want to make use of the codec you\u0026rsquo;ll need to use the older kernel provided by Allwinner, and their cedar core.\nCedrus is an open source alternative that makes use of community documentation of the codec registers. It\u0026rsquo;s available upstream in the kernel. Great! Except it only handles decoding not encoding. :(\nSearching around I found some older posts talking about hw encode on the Allwinner H3.\nhttps://forum.armbian.com/topic/11551-4kp30-video-on-orange-pi-lite-and-mainline-hardware-acceleration/page/2/#comment-89815\nThey mentioned these components:\nhttps://github.com/uboborov/sunxi-cedar-mainline https://github.com/uboborov/ffmpeg_h264_H3 https://github.com/uboborov/cedrus sunxi-cedar-mainline This is a kernel module which when loaded creates /dev/cedar_ve. This file facilitates the interaction from a userspace app to the low level codec block. What is interesting is that this project specifically list Kernel 5.7, with config. It makes use of the CMA, Continuous Memory Allocator, a part of the Linux mainline Kernel. Many repos for \u0026ldquo;cedar\u0026rdquo; seem to use an older ION system from Android, and are pinned to old kernel versions.\nffmpeg_h264_H3 This is a custom encoder that compiles into FFmpeg. Unfortunately this version does make use of ION, which creates a bit of a disconnect between the kernel module and the userspace code\u0026hellip; :/\ncedrus These small utilities are super handy, they\u0026rsquo;re small single purpose applications h264enc, jpeg-test, mpeg-test.\nThe code makes use of the CMA, and also the functions and code layout match up pretty perfectly to the FFmpeg encoder code. Combining this code into the FFmpeg looks like it might be the way to go.\nBuilding So it looks like we have all the pieces for this puzzle but can we put them together..\nA very simple package is added buildroot project to compile the kernel module, this also installs the module into the target filesystem.\n################################################################################ # # cedar-mainline # ################################################################################ CEDAR_VERSION = cb9ea3d9894fd88a5b7f67fea220ceaa5ed17656 CEDAR_SITE = $(call github,gregdavill,sunxi-cedar-mainline,$(CEDAR_VERSION)) CEDAR_LICENSE = GPL-2.0 CEDAR_LICENSE_FILES = LICENSE $(eval $(kernel-module)) $(eval $(generic-package)) Along with the kernel module, we need to enable the CMA, because we only have 128MB to work with I first started with 64MB.\ndefconfig + CONFIG_DMA_CMA=y + CONFIG_CMA_SIZE_MBYTES=64 sun8i.dtsi reserved-memory { #address-cells = \u0026lt;1\u0026gt;; #size-cells = \u0026lt;1\u0026gt;; ranges; cma_pool: default-pool { alloc-ranges = \u0026lt;0x40000000 0x8000000\u0026gt;; // Start Addr + Length compatible = \u0026#34;shared-dma-pool\u0026#34;; linux,cma-default; reusable; alignment = \u0026lt;0x2000\u0026gt;; size = \u0026lt;0x4000000\u0026gt;; /* 64MB */ }; }; syscon: syscon@1c00000 { compatible = \u0026#34;allwinner,sun8i-v3s-system-controller\u0026#34;, \u0026#34;allwinner,sun8i-h3-system-control\u0026#34;, \u0026#34;syscon\u0026#34;; reg = \u0026lt;0x01c00000 0xd0\u0026gt;; #address-cells = \u0026lt;1\u0026gt;; #size-cells = \u0026lt;1\u0026gt;; ranges; sram_c: sram@4000 { compatible = \u0026#34;mmio-sram\u0026#34;; reg = \u0026lt;0x4000 0xa000\u0026gt;; #address-cells = \u0026lt;1\u0026gt;; #size-cells = \u0026lt;1\u0026gt;; ranges = \u0026lt;0 0x4000 0xa000\u0026gt;; ve_sram: sram-section@0 { compatible = \u0026#34;allwinner,sun8i-v3s-sram-c\u0026#34;, \u0026#34;allwinner,sun4i-a10-sram-c1\u0026#34;; reg = \u0026lt;0x000000 0xa000\u0026gt;; }; }; }; ve: video-engine@01c0e000 { compatible = \u0026#34;allwinner,sunxi-cedar-ve\u0026#34;; reg = \u0026lt;0x01c0e000 0x1000\u0026gt;, \u0026lt;0x01c00000 0x10\u0026gt;, \u0026lt;0x01c20000 0x800\u0026gt;; memory-region = \u0026lt;\u0026amp;cma_pool\u0026gt;; syscon = \u0026lt;\u0026amp;syscon\u0026gt;; clocks = \u0026lt;\u0026amp;ccu CLK_BUS_VE\u0026gt;, \u0026lt;\u0026amp;ccu CLK_VE\u0026gt;, \u0026lt;\u0026amp;ccu CLK_DRAM_VE\u0026gt;; clock-names = \u0026#34;ahb\u0026#34;, \u0026#34;mod\u0026#34;, \u0026#34;ram\u0026#34;; resets = \u0026lt;\u0026amp;ccu RST_BUS_VE\u0026gt;; interrupts = \u0026lt;GIC_SPI 58 IRQ_TYPE_LEVEL_HIGH\u0026gt;; allwinner,sram = \u0026lt;\u0026amp;ve_sram 1\u0026gt;; }; A lot of the references I\u0026rsquo;ve seen online to working with this codec seem to set sram_c to 0x1d00000. Which seems to be an empty section of memory, according to the official memory map. So I\u0026rsquo;ve set my device tree to point to the sram_c defined in the S3 datasheet, this seems to work correctly, atleast for my use cases.\nKernel output [ 0.000000] Reserved memory: created CMA memory pool at 0x43c00000, size 64 MiB [ 0.000000] OF: reserved mem: initialized node default-pool, compatible id shared-dma-pool ... [ 0.000000] Zone ranges: [ 0.000000] Normal [mem 0x0000000040000000-0x0000000047ffffff] [ 0.000000] HighMem empty [ 0.000000] Memory: 50136K/131072K available (8192K kernel code, 1478K rwdata, 2800K rodata, 1024K init, 240K bss, 15400K reserved, 65536K cma-reserved, 0K highmem) ... # modprobe cedar_ve [ 9.202456] cedar_ve: loading out-of-tree module taints kernel. [ 9.210073] sunxi cedar version 0.1 [ 9.213939] [cedar]: install start!!! [ 9.217684] cedar_ve: cedar-ve the get irq is 23 [ 9.222323] sunxi-cedar 1c0e000.video-engine: assigned reserved memory node default-pool [ 9.230624] [cedar]: Success claim SRAM [ 9.338704] [cedar]: memory allocated at address PA: 43D00000, VA: C3D00000 [ 9.345749] [cedar]: install end!!! Success! 🥳\nThe first time I tried this I hit an error trying to allocate memory, because it was attempting to allocate 80MB. Easy fix. Might be better suited to be set up the ve_size as a device tree parameter.\ndiff --git a/cedar_ve.c b/cedar_ve.c index 2f6f744..c73ea88 100644 --- a/cedar_ve.c +++ b/cedar_ve.c @@ -1804,7 +1804,7 @@ static int cedardev_init(struct platform_device *pdev) #endif /*LINUX_VERSION_CODE \u0026gt;= KERNEL_VERSION(4,11,0)*/ #if !defined(USE_ION) -\tcedar_devp-\u0026gt;ve_size = 80 * SZ_1M; +\tcedar_devp-\u0026gt;ve_size = 32 * SZ_1M; ret = dma_set_coherent_mask(cedar_devp-\u0026gt;dev, DMA_BIT_MASK(32)); if (ret) { dev_err(cedar_devp-\u0026gt;dev, \u0026#34;DMA enable failed\\n\u0026#34;); New we have the kernel module loaded it\u0026rsquo;s time to set up FFmpeg. Here is a diff I\u0026rsquo;ve applied to FFmpeg 4.4\nResults Not an apple to oranges comparison, because the h264 parameters are different. But you can see even on the \u0026ldquo;ultrafast\u0026rdquo; preset, the speed can\u0026rsquo;t keep up with a measly 30 fps 640x512 stream.\n# ffmpeg -f v4l2 -video_size 640x512 -pix_fmt nv12 -i /dev/video0 -r 30 -c:v cedrus264 -vewait 5 -b:v 4M -maxrate 4M -qp 30 -t 5 -f mp4 test.mp4 -y frame= 150 fps= 30 q=-0.0 Lsize= 558kB time=00:00:04.96 bitrate= 921.1kbits/s speed=0.994x # ffmpeg -f v4l2 -video_size 640x512 -pix_fmt nv12 -i /dev/video0 -r 30 -c:v libx264 -b:v 4M -maxrate 4M -bufsize 1M -preset ultrafast -t 5 -f mp4 test.mp4 -y frame= 150 fps= 20 q=7.0 Lsize= 2380kB time=00:00:04.96 bitrate=3925.5kbits/s dup=24 drop=0 speed=0.66x I\u0026rsquo;ve only really started to poke around with the encoder support. But hope this write-up encourages you to give it a spin too! I\u0026rsquo;d love to see any projects you come up with utilizing the Allwinner S3!\n","permalink":"https://gregdavill.com/posts/allwinner-s3-videoencoders/","summary":"Introduction I\u0026rsquo;ve been using an Allwinner S3 SoC for experiments with the FLIR Boson. The description from the website sums the device up nicely:\nS3 is a high cost-effective video encoding processor jointly developed by Zhuhai Allwinner Technology Co., Ltd. (\u0026ldquo;Allwinner\u0026rdquo;) and Sochip Technology Co., Ltd. (\u0026ldquo;Sochip\u0026rdquo;). Its built-in single-core ARM Cortex-A7 runs at 1.2GHz with 1Gbit DRAM (DDR3) , supporting numerous peripheral devices. The Chip package is 234 balls FBGA package, size 11mm x 11mm , suitable for various types of product development.","title":"Allwinner S3 Video Encoders"},{"content":" Summary Texas Instruments has a range of 16 bit microcontrollers, the MSP430. To program these require what they call a Flash Emulation Tool (FET).\nThankfully all their affordable development kits contain a small stripped down FET, known as the ezFET Lite. TI has open sourced this design and provide both the firmware and the schematics. I was given a tag-connect cable as a giveaway through the 43oh, MSP430 community forum. I decided to create a custom PCB to connect directly to the tag-connect cable.\nHere is a forum post I made when I\u0026rsquo;d designed this: https://forum.43oh.com/topic/5530-custom-ezfet-lite/\nSchematic Downloads This design was done in Altium when I was still studying at uni and had a \u0026ldquo;cheap\u0026rdquo; licence.\nezFet_lite_tagConnect_0_01.zip v0.1 had some issues around the inrush current and lack of bulk capacitance causing it to disconnect from the host when attached to a target. I designed a v0.2 that had these fixes, but unfortunately did not save those files.\n","permalink":"https://gregdavill.com/posts/ezfet-summary/","summary":"Summary Texas Instruments has a range of 16 bit microcontrollers, the MSP430. To program these require what they call a Flash Emulation Tool (FET).\nThankfully all their affordable development kits contain a small stripped down FET, known as the ezFET Lite. TI has open sourced this design and provide both the firmware and the schematics. I was given a tag-connect cable as a giveaway through the 43oh, MSP430 community forum.","title":"MSP430 custom ezFET Lite"},{"content":"I\u0026rsquo;d recently bought a new XPS13 7390 (non 2-in-1) laptop. I had bought the 8GB variant, how hard could it be to upgrade?\nI use my laptop for KiCad PCB design, compiling embedded firmware, and FPGA synthesis. None of these really use that much RAM. But if you leave tabs open in Firefox or Chrome and also perform other work you\u0026rsquo;re easily going to exceed 8GB. I\u0026rsquo;ve done so many times, on my ubuntu install the system basically grinds to a halt as the kernel scrambles to unload pages from DRAM into SWAP.\nI knew the DRAM in my new laptop was soldered to the main board when I bought it. But I\u0026rsquo;m an electronics engineer, and reasonably proficient at BGA rework. So this begs the question, How hard is to actually upgrade?\nInitial Research (asking on twitter) I had my old laptop, an XPS13 9350 that contained 16GB of LPDDR3, contained in 4 separate ICs. This means that each IC contained 4GB, (or 32Gbit). I was curious about performing a direct swap from the old system to the new one.\nI posed the question on twitter.\nI\u0026rsquo;m curious about upgrading the DRAM on my new XPS. 8CB -\u0026gt; 16GB.\nI have my older XPS MB with perfectly good LPDDR3 chips, I\u0026rsquo;m confident I could do the rework to transplant them.\nWould the BIOS just pickup on the extra RAM? or is there other SW steps involved?\n— @gregdavill\nI honestly didn\u0026rsquo;t expect much from this tweet, but whitequark replied with a concrete answer!\nwhich exact models? on 9350/9360 there are hard straps. I suspect it will be the same on newer but I\u0026rsquo;d need to check schematics to be sure.\n— @whitequark\nNot only was this super helpful, she went multiple steps further! locating a schematic and board view for my laptop, to verify these resistor straps.\nWith the board view I was able to locate the resistor strap on my mainboard\nThere was also a hackaday.io project I found of someone doing the same procedure but on their MB pro.\nHow socketed RAM works If you\u0026rsquo;ve ever taken a close look at a SODIMM that you might use in a laptop with \u0026ldquo;user upgradable\u0026rdquo; memory. There are the RAM ICs, plus an extra small IC, typically a 8-pin TSSOP part. This is known as the SPD, Serial Prescence Detect. Essentially the RAM ICs on a SODIMM are just that, RAM. They don\u0026rsquo;t contain any method or mechanism to query what capacity/speed they are. So instead of performing an exhaustive self-test over the entire memory array to detect what RAM is installed in a system, SPD was created. It\u0026rsquo;s essentially just a small EEPROM that describes the ICs that are installed on a given SODIMM.\nWhen laptops started moving memory onto the mainboard, instead of in sockets, they still needed a mechanism to emulate SPD info, so that your OS can correctly detect and show you information about the memory installed in your system. Instead of populating an EEPROM, they simply embed this info inside the BIOS FLASH. Part of the BIOS boot sequence is to extract an SPD table from FLASH, and create a virtual SPD that the OS can query.\nHow does this help us Knowing that there was a 16GB model of my laptop available to buy helps here. Dell release the same BIOS update for the XPS no matter what RAM is installed, so they use resistor straps on GPIO pins of the CPU to detect various mainboard variants. These values are published right in the schematics\nYou can see here a series of 5 \u0026ldquo;strap\u0026rdquo; resistors, and a table which shows that they can be populated in various arrangements. Note: the table specifies specifically 2133Mbps, and shows values for Hynix, and Samsung parts in 4/8/16G variants.\nGreat! I suppose the next step will be to jump onto a component distributors website and buy some new ICs right?\nBuying new chips As it turns out, LPDDR3 memory isn\u0026rsquo;t really stocked through standard distributors. Digikey only had a fow listings for lower density parts, at slower speeds. To source these parts I might have to get creative.\nWhat got me started on this idea was that both my old XPS13 (9350) and the new one (7390) both use LPDDR3. Would it be possible to list the parts from the old mainboard and install them on the new one? Well, probably not. Remember how I mentioned that the schematic specified 2133Mbps? Well the LPDDR3 from my old mainboard was only rated at 1866Mbps.\nWhitequark pointed out that there are some other dell laptops which use the same 5 resistors straps, and show a larger table of memory options. Maybe they left the extra SPD tables in the BIOS? I think I had certainly nerd-snipped her at this point, because she went as far as decompiling the BIOS and extracting part numbers of all possible strap configurations, and deemed that only the values shown on the schematic were present.\nSo looks like I will need to find some 32Gbit 2133Mbps ICs. It\u0026rsquo;s possible to pick up mainboards from ebay that would have the parts. But that can get to be a bit expensive, especially since many laptop mainboards also contain a soldered down CPU.\nSo I went to aliexpress, typed in a part number that was extracted from the BIOS\u0026rsquo;s SPD data; H9CCNNNCLGALAR-NVD and would you look at that.\nI bought exactly 4, 2x \u0026ldquo;New Original 2pcs\u0026rdquo;. I placed an order on Jan 2nd 2021 from this listing.\nReliable+Professional=We? Yes, Indeed!\nNow the fun begins Feb 19th 2021: A package arrives. They do in fact look \u0026ldquo;New Original\u0026rdquo;!\nHaving checked out the boardview for the motherboard I now know it\u0026rsquo;s an 8L design with 3/4 ground-planes throughout. So quite challenging on the rework side. Not wanting to ruin a perfectly functional laptop, I decided to practice on my older laptop main board first.\nUsing my hot-air gun a Quick 861DW, and a no-brand pre-heater under the PCB I started to remove these old LPDDR3 parts. It was a good thing I practiced, because to overcome the multiple ground planes you really do need to pump a lot of heat into the PCB before the lead-free solder begins to melt.\nAre the new parts even genuine? Even though they weren\u0026rsquo;t super cheap, I wasn\u0026rsquo;t sure if they were actually genuine or not. The first check was that yes in-fact the ball pattern matched LPDDR3. My second check, I used a bit of acetone on a cotton swap to rub the top of the IC, if the IC were cheaply re-marked with paint/laser then this might reveal a fake. No paint came off with the acetone.\nLastly, and this is definitely overkill. I had a dentist take an xray of the new and old parts.\nSo clearly what I had was a DRAM part, you can see a die inside there and also the bond-wires running up to the dies from the substrate. What\u0026rsquo;s fascinating to me is the fact that you can clearly see this is a multi-stacked die, one way they\u0026rsquo;re able to fit 32Gbit inside a single chip. And the fact that the new/faster SK Hynix parts are making use of a considerably smaller die! It only takes up half the total package, compared to the older LPDDR3 where the dies is the majority of the package.\nSo even after the xray I\u0026rsquo;m still left without an answer. But I can really only assume that it is a genuine part, and solder it down.\nSoldering BGA parts De-soldering BGA parts is pretty straight-forward; Apply heat, when solder melts lift up IC. Of course there is a fair amount of skill involved, practice helps!\nOnce you\u0026rsquo;ve removed a BGA part, some solder is left on the PCB. But some remains on the part. This doesn\u0026rsquo;t happen evenly across a part. So if you attempt to solder that part back down to a different PCB then some connections may have too much solder, and others not enough.\nIf you wish to re-populate a BGA part that you\u0026rsquo;ve removed you really do need to perform \u0026ldquo;BGA re-balling\u0026rdquo;. I wanted to practice this, so I bought a BGA re-balling kit, and a stencil for the LPDDR3 parts.\nThe first step is to remove all the existing solder from the IC, and clean off all residue and flux. With the part loaded into the jig, a thin layer of flux is applied to the IC, and the stencil is aligned\nSolder balls are added to the jig, and spread over the openings in the stencil.\nAfter clearing balls from the openings you can lift the stencil up\nNote that you could see the balls weren\u0026rsquo;t perfectly aligned in the last image, and this resulted in a pretty bad time. No worries, just return to step 1 and start again.\nIf you get everything right you can have a perfect looking part, read to be soldered down\nI got pretty confident in my re-balling, and actually re-balled all of the new LPDDR parts. This removed the lead-free solderballs and replaced them with leaded solder. My lab is generally a lead-free space. However in this case the lower melting point would help my chances of success with soldering down the new ICs.\nUpgrading the RAM With enough practice to be confident in my abilities, I created this little graphic, showing the exact resistor I needed to move. Nothing else to do but to actually swap the RAM chips.\nThe XPS13 comes apart pretty easily with only a few external torx screws, then phillips screws throughout the inside of the machine\nHere is the installed LPDDR3 parts, these need to be removed.\nBut first a quick break to refuel. With a hot Milo, and hot cross bun. Yumm.\nHere is my setup, IR pre-heater, main-board, and fume-extractor. Not pictured is a stereo microscope above this stack.\nWith all my practice the RAM came off without an issue\nAfter the ICs were removed I used solder wick to remove any excess solder, then cleaned up the area with IPA.\nNew RAM installed\nAnd strap resistor moved, so hopefully the BIOS will know there is 16G present.\nIs that it? A small strike of panic as I pressed the power button for the first time after putting most of the machine back together. In order to work on the main-board I had removed the CMOS battery. Turns out the XPS will take a solid 30-60s to boot up after the CMOS battery has been removed and replaced.\nPhew.\nBack into the BIOS and look! It\u0026rsquo;s detected it!\nBut this is probably expected, simply due to the straps. The BIOS doesn\u0026rsquo;t actually run any memory checks. So likely you could get this result even if the 8GB was still installed.\nExiting the BIOS the computer booted normally in to the OS. This is a good sign. It\u0026rsquo;s unlikely that an OS could boot if the reported RAM didn\u0026rsquo;t actually all work. I ran a quick check from the OS on the SPD. Which looks good, mimics what we saw in the BIOS.\nFinal Testing With an OS booted I was pretty sure that the ICs were in fact genuine. But to ensure system stability, and to ensure that I\u0026rsquo;d actually soldered them down correctly you do want to perform an exhaustive memory test. So as a final step I fired up memtest86. and let it run through.\nIt passed through 4 passes of all its tests without issue! This shows that all the memory space is functioning and my RAM upgrade was a success!\nConclusion I\u0026rsquo;ve now got an XPS13 with 16GB of memory.\nBut next time I think I\u0026rsquo;ll just buy the 16GB variant upfront.\n","permalink":"https://gregdavill.com/posts/dell-xps13-ram-upgrade/","summary":"\u003cp\u003eI\u0026rsquo;d recently bought a new XPS13 7390 (non 2-in-1) laptop. I had bought the 8GB variant, how hard could it be to upgrade?\u003c/p\u003e","title":"Dell XPS13 RAM Upgrade (7390)"},{"content":"Still alive? 🪦 Yes, it\u0026rsquo;s true this project did get dropped for awhile, it\u0026rsquo;s been about 3 years since the last blog post.\nDigital video Adapter (DiVA) After implementing the SD controller I had kind of got to a limit of what I could get the hardware to do. Recall that this project was my first foray into FPGAs. However after seeing this project, GroupGets reached out interested in working on a digital video adapter PCB. The idea being a way to adapt the Boson to a digital video stream, like DVI or HDMI. FLIR already provide a \u0026ldquo;VPC\u0026rdquo; breakout, which stands for Video, Comms, and Power. However this cable provides composite video output, which isn\u0026rsquo;t great if you want to persevere the quality, or if you want to capture the full dynamic range.\nSo that\u0026rsquo;s one of the boards I designed. Here are some assembly photos from the initial prototype to show that it was possible.\nThe PCBs were put into a small panel to make them a bit more manageable to assemble. The panel has some non-plated through-holes around it\u0026rsquo;s frame that align with features I put onto the stencil. This enabled the use of some 1.6mm steel pins to perfectly align the stencil to the PCB.\nThis actually works really well, the main issue I\u0026rsquo;ve seen is that you don\u0026rsquo;t want the pins to interfere with the squeegee action, here they are protruding a bit too high from the top of the stencil.\nSolderpaste went down well, I\u0026rsquo;m using Loctite GC-10 here. The T4 variant.\nYou can see in this image that I forgot that the HDMI connector has pins that protrude through the PCB. So if I had reflowed the connector I would not be able to sit a stencil flush with the second side of the PCB. Doh.\nThe fix was pretty simple, leave the connector off, reflow, then assemble the second side with an additional reflow cycle then hand solder on the HDMI connector.\nFor extra units I simply soldered the FPGA side up first.\nYou can see the device very much resembles the boson-frame-grabber design.\nYou do need to be careful with the 80-pin Hirose mezzanine connector. You really want to keep the two mated PCBs parallel when removing them. I unfortunately damaged a connector removing it.\nThe full sized HDMI connector is a bit ridiculous given the size of the camera. So altough I typically don\u0026rsquo;t like micro HDMI connectors, this was actually quite a nice fit for this camera\nThis prototype did work. However because I didn\u0026rsquo;t include any RAM, the FPGA is only able to output a similar resolution, 640x512. In this case 640x480, with top/bottom rows of pixel removed.\nThis restriction is because we are essentially capturing a stream of pixels, and have to also output a stream of pixels to the display. In order for us to not run-out of pixels to send to the display We need to run the output clock rate a something very similar to the input.\nEven with this hiccup, the prototype proved the design could work. So with the proof of concept done I started work on the design for a more production ready variant.\nInital production prototypes Here is the initial production version, which turned out to have some layout bugs and issues.\nYou can see I\u0026rsquo;ve added the hyperRAM back to the board, and also added USB C for power/and comms. The USB passes through a mux so you can use the Boson UVC device or talk to the FPGA at USB FS speeds. The USB is used to implement a bootloader that lets you update the device firmware/gateware.\nHere is shot of the final production variant, that are available now on the group-gets store: https://store.groupgets.com/products/flir-boson-digital-video-adapter\nDiVA gateware The hardware for this camera is not open-source. But the gateware/firmware is! You can find that here: https://github.com/gregdavill/DiVA-firmware\nAs an example of what the device does here is a capture of it\u0026rsquo;s output, with on-screen menus.\nThe current stable gateware is based on LiteX and Serv, LiteX is a collection of CPUs and peripherals along with plumbing to connect them all up. It\u0026rsquo;s written on top of migen, a method to describe and generate verilog from python. Serv is a serial RISCV implementation. It\u0026rsquo;s interesting because it\u0026rsquo;s quite small, therefore can run a quite a high frequency. However that higher frequency does need to overcome the fact that all instructions take at least 32 times longer to execute, because it\u0026rsquo;s a serial CPU, it\u0026rsquo;s internal data-path is only 1 bit wide, so to operate as a RISCV-RV32 it needs lots of extra cycles.\nCompared to raw verilog, going around and finding cores, then connecting them together in a SoC design. I find using LiteX way more productive, but there is a bit of a learning curve.\nThe gateware that runs DiVA is essentially a SoC, HyperRAM controller, DMAs, and TMDS serializer. These components work together to capture a frame from the camera into memory, and then queue that frame for transmitting back out through the serializer.\nv1.2 of the gateware also introduced a video scaler, which does appear to work, but might be distorting colours a bit, since it\u0026rsquo;s just combining R,G,B values linearly with coefficients from the scaler. I\u0026rsquo;ve been told that \u0026ldquo;proper\u0026rdquo; upscaling likely requires converting to a different colour space, combining colours, then converting back to RGB.\nThe scaler is a simple design I came up with after watching some lectures on multi-tap \u0026ldquo;polyphase\u0026rdquo; filters. The scaler only performs the up-scale operation. A stream of pixels comes through 4 \u0026ldquo;taps\u0026rdquo;. These taps cycle through coefficients that are loaded by the CPU. The coefficients have a flag to stall incoming pixels, but increment to the next step. This enables the upscaling operation. These coefficients are pre-calculated and match with a bilinear interpolation of the input to output ratio of scaling we want to achieve. I\u0026rsquo;ll probably try to make a more detailed blog post about that at some point.\nThe scaler can perform various stretch operations, since different coefficients are used for X/Y.\nFill (crops top/bottom) Fit (borders on left/right) Center 1:1 Full Screen (Changes aspect ratio) There is also some buffering logic in there to enable coefficient banks to swap at the end of frame, to avoid graphical distortions while switching scaling options.\nUpdated DiVA gateware There are a few open issues with the existing DiVA gateware, notably that it currently only supports 800x600 output resolution. And many HDMI transmitters expect at least 1280x720.\nThe hardware should technically support this, but someone needs to sit down and write the gateware to do it. I have started, but it\u0026rsquo;s far from complete yet.\nI do also have plans to update the video pipeline to support more \u0026ldquo;modern\u0026rdquo; looking GUIs. But that work isn\u0026rsquo;t completed yet. For the time being, here is a demo image, showing various GUI elements ontop of a noise source. Also note that it\u0026rsquo;s output at 1280x720 resolution.\n","permalink":"https://gregdavill.com/posts/boson-frame-grabber-pt6/","summary":"\u003ch1 id=\"still-alive-\"\u003eStill alive? 🪦\u003c/h1\u003e\n\u003cp\u003eYes, it\u0026rsquo;s true this project did get dropped for awhile, it\u0026rsquo;s been about 3 years since the last blog post.\u003c/p\u003e","title":"Boson Frame Grabber Part 6"},{"content":" A tennis ball sized, 20 sided, LED clad, regular polyhedron\nIntroduction The major challenge of making a smaller LED cube in my opinion is the LED panels. Commercially available panels are designed for video walls and typically made at 64x64 pixel as a minimum size. This seems to be a good trade off between cost/complexity/light efficiency. On my previous project mini-led-cube I had overcome one of the major hurdles of creating a smaller cube, because I had designed and built my own custom high density* LED panels.\n(*high density: less than 2.5 mm pixel pitch)\nSo what next? I could make it smaller, improve the controller, improve the firmware. What about adding more sides?\nInspiration came from this origami figure that I’d built many years ago and that has been sitting on my shelf.\nI’d never seen a LED icosahedron before\u0026hellip; Design decisions I started by thinking about at a birds-eye view of the project, what major aspects there would be. What I know I wanted from a design point of view, and what I still had to work out. Engineering projects are always about problem-solving, so it helps to have a clear view of the problems that lie ahead of you.\nPanels I would need to design a LED panel that was compact and contained all the electronics. This panel would be in the shape of an equilateral triangle, and have a method to connect it easily to other panels to form a chain. How would I arrange the LEDs on the surface of each panel to assist in routing. Knowing the panels were at different angles I would like them them to align no matter what orientation they were fitted in. 120 degree symmetry. Enclosure How will the panels be held together with minimal bezels 3d printing is an obvious answer since this enclosure has lots of weird angles Probably a 3d printing service that does resin or nylon Resin is discounted due to personal experiences with in being brittle and discolouring over time Want a black material, so the case isn’t noticeable Total overall size? Thinking tennis ball/rubiks cube sized to match the cube Controller Can make use of controller design for the cube, will need to be re-designed to fit in the smaller form-factor Power How will this be powered? 18650. RC hobby LiPo cells? I want to be able to carry this on a plane, will probably require something a little bit more friendly looking. Timeline I’m super late in writing this blog post. I started thinking about this project in September 2019, and want it ready to take to supercon 2019. Which I was leaving my lab on the 2nd of November. So I had a little under 2 months to pull it off. Design Stage At this point I had an idea in my head about what I wanted the device to look like. However there were no hard or fixed numbers yet. So I knew I needed to work out the dimensions of each panel first. I did this in my 3d CAD of choice, fusion 360. I looked up a tutorial about how to model an icosahedron, which was more complex than you might imagine. Once modeled, I scaled it to be roughly tennis ball sized, this left me with a triangular face with sides of 42mm. From this I inset slightly to give room for the panels to be sunken down into the enclosure.\nI had used 2x2mm LEDs for the cube, and knew they came in a smaller variant, 1.5x1.5mm. These would be perfect. They feature a black casing that helps highlight the round lens on the top. This is particularly important because as you move this around, some panels the LEDs might be rotated, but so long as round opening is in the same location you generally won’t notice.\nYou can get smaller LEDs, however these create some more challenges. I need to be able to route this board easily and didn’t want to start using HDI features. (Blind/buried vias). To achieve this a trace needs to be run through the middle fo the LED pads, this isn’t possible with these smaller 1x1mm or 0.7x0.7mm RGB LEDs. Secondly because they don’t feature the black enclosure I was worried that light bleed between pixels would be bad.\nBased on the experience I had with the cube I knew I could create a matrix arrangement for the LEDs, and make use of the 16bit constant-current LED drivers + 595/PMOS source drivers.\nThe TLC59025 sink drivers are set to a single current for the entire 16bits it’s a requirement to use 3, one each for R,G,B. This is because each colour will require a slightly different current to produce a nice white. I say “style” because you can find multiple pin compatible drivers. lcsc sell a few that have Chinese only datasheets, but because they’re designed as drop-in replacements that isn’t an issue. You can save quite a bit of money using these. Especially given I needed to use 60 of these in the project.\nThese drivers only turn ON/OFF they don’t handle any greyscale control themselves. Because of this you do want to connect both the LATCH and BLANK signals. This enables you to clock new data in while current data is being displayed. As well as control the exact interval data is displayed for. This and some FPGA logic is what enables high refresh rate greyscale control.\nThe architecture is shown above. There are a few interesting observations.\nI placed everything in a single serial string. This represents 64bits from input to output, and is primarily to reduce the pin count of the connectors, and hence the internal wiring. r0.1 boards did not have buffers, but I noticed after 3 panels there was some glitches. So I added those. I’ve include enough electronics to drive an entire 16x16 matrix, but only populate a triangular portion of it. This GREATLY helps with signal routing. I’m already at 4L to route power/signals on inner layers, but I tried routing it with just a single 8bit source driver, and failed. I opted for 6-pin 0.5mm pitch flat flex cables. These were actually a little bit tricky to find, ended up buying various lengths from an aliexpress seller. With the space available I am able to fit a triangular array of LEDs with 15 pixels across the base and 15 pixels high. this comes out to 120 LEDs per side.\nWith 20 sides this results in 2400 LEDs total. This will be fun to hand place! but I’ll leave that for future Greg to worry about.\nPanel r0.1 Shown above is the panel I sent off to have made at JLC PCB. (https://jlcpcb.com/) They were kind enough to provide free PCBs and stencils for this project.\nI placed this order on the 12th of September.\nThe boards arrived ~1 week later. And they looked good on the surface. I went to assemble one, and when trying to determine the LED orientation I discovered a fatal flaw. I had the footprint rotated 90 degrees. (-___-)\nI attempted to assemble a board bey placing LEDs at 90 degrees, but ultimately this was a failure, the pads look reasonably symmetrical, but they’re not exactly. So when placing the LEDs at 90 degrees there isn’t great surface tension during reflow to pull them into alignment. Yep, that alignment looks pretty ugly.\nAlso worth noting that because I did not have the FFC cables or connectors at this point, and I had not written the code to drive the display, I didn’t even attempt at powering this on. Maybe you can sense the foreshadowing, in this observation.\nPanels Take two Everything else about the panels seemed fine at that time, so I quickly adjusted the footprint. ripped up the top layer and re-routed. I had a bit of creative energy/motivation left at this point so I added 2 little dual input buffers to the design, This helps isolate each panel from the next. Particularly the clock line, and removes some glitches I was seeing on the cube design. With the routing complete I placed the order again with JLC, this time I just payed for the boards myself, because I was now on a tighter deadline and I didn’t feel like asking for more free stuff because of a dumb mistake on my end.\nI placed this order on the 10th of October\nEnclosure Let\u0026rsquo;s switch gears to the enclosure, with a design for the panels done I can export a 3d model from KiCad and start looking at how they’ll be integrated into an enclosure. I did have to model up a custom LED. Which was very useful to see how everything would be fitting.\nThe panels fit great, and the bezels looked thick enough to be manufacturable, now it was just a matter of going through and cutting away as much of the enclosure as possible. Nylon MJF prints are priced by they’re total size and how much total material ends up in the final print.\ncould not find image could not find image could not find image With regard to powering the device I managed to fit a Sony mirror-less camera battery in the enclosure, and even more surprising I found a compatible 3-pin terminal that actually fit the battery! (That’s one of the challenges of using this style of battery).\nI needed a way to insert/remove the battery, and I’d determined it was easiest to remove a section of the icosahedron with 5 panels in it, these 5 panels would have a single ribbon cable running between it and the base. The sections would have asymmetric locking features and magnets, so it could be securely fastened and removed.\ncould not find image I even tried to be clever and add locking features to the 3d print to retain the controller PCB. Fusions “look-at” [face] option and the section-analysis were vital in getting this designed.\nWith the two halves designed, and checked multiple times over a few days I was ready to order them. I don’t really know too many options around for quickly prototyping a Nylon MJF part, so I just opted for shapeways. I opted for their higher detail service, with express options. The order totalled $167.68 USD. I was hoping there wasn’t any issues with the design I’d overlooked, especially considering this was my first time designing a Nylon MJF part.\nI placed this order on the 12th of October.\nController I’d re-designed the controller, basically an exact replica of the one used on the cube, but with 4x 6 pin FFC’s out to the displays. The controller and enclosure were designed in tandem, there was a bit of back and forth to get everything to fit correctly. Thankfully this is pretty seamless with the dxf import in KiCad and the 3d STEP output.\nThe controller is based around a fast programmable SAMD51, this is an M4 core that can run up to 120MHz. Also, because the project wasn’t complex enough I decided I’d like to use rust to drive the system. And there are rust crates and support packages for the samd51.\nA button and USB connection ensure an easy way to update the firmware on the device, since access to the JTAG connector will be tricky once everything is assembled.\nThe ice40 FPGA offloads all the real-time display multiplexing, it outputs pixels to the 4 strings of panels in parallel, and achieves ~100Hz update rate from the frame buffer, while outputting gamma corrected 10 bit binary coded modulation for grayscale control over each pixel.\nOn the power supply front, it would have been nice to have a battery charger, but these Sony batteries are 7.4V nominal, which makes charging a tad more complex than just dropping in a single chip solution. I did still want tho device powered over USB when programming/debugging, so I added an ideal diode controller, which efficiently combines two input power sources. I also added a basic under voltage monitor to the battery to ensure that I didn’t over discharge the LiPo cells (Although I’ve now discovered that they might have this built in.)\nThis is the model I’d created for the controller. This is straight out of KiCad, and was essential to ensure a good mechanical compatibility between the PCBA’s and enclosure.\nI ordered these on the 10th October.\nAssembly Stage could not find image Circuit boards arrived on Friday 18th Oct.\nRapidly running out of time, I know I wanted to get a controller built, so I could start playing with the firmware. Also some LED panels built, so I could do a test-fit on the enclosure that would show up the following week. I got into a rhythm and ended up assembling the controller side on all the LED panels.\nThe soldering went great. I am using SAC305 Pb free paste, and stainless steel stencils that JLC provided with the PCBs.\nWith the controller side done I set up a jig to align the stencil on the top layer and apply solderpaste. I opted to do the LED side last mostly so that the LEDs only had to run through a single reflow cycle. I made a jig out of old PCBs to hold the panels by their rails in the oven, so that underside components were not touching anything. Surface tension should keep them all in place, but if a force was applied while the solder is molten there is a chance that they would move.\nWith solder applied to the PCB I placed the parts using a syringe with a blunt / bent dispensing needle. The syringe is connected to a small DC vacuum pump. This creates enough pressure to pick up parts from tape, and then when placed onto the solderpaste the extra force from the paste is enough to pull them off the syringe.\nI set up a wooden board on my table and used double-sided tape to stick down strips of the LED cut-tape, all in the same orientation. The PCB is positioned such that the LEDs just have to be moved, not rotated.\nI also built up a controller PCB. Also using solderpaste + reflow oven. And the enclosure arrived!\nEnclosure Test-fit The enclosure looked great! The texture from the MJF was a perfect fit with the look of the PCB/LEDs. The tolerance between the parts I had estimated perfectly. The magnets fit in both parts (One problem was I couldn’t actually get the magnets out.)\nThe controller board and battery fit great in the enclosure. So now it was time to dive into the firmware/gateware and get the LED displays working.\nFirmware and Mistakes I’d been putting this step off for a little while, because the gateware needed to be altered from the cube in order to drive this new panel type. The row and column data needed to be encoded into a 64bit pattern and then sent out to each display in the string.\nI coded this change up in a simulator, and confirmed that I was getting the correct signals out. So I hooked it up to an icebreaker (ice40 development board) and run my gateware. Nothing.\n\u0026hellip;\nNothing happened.\nThis is not really unsurprising to be honest. There are a lot of things that need to be set correctly in order for code that looks correct in a verilog simulator to run correctly on hardware. So I powered up my scope and began probing around.\nSignals coming out of the FPGA: OK Signals appearing on the shift register inputs: OK Blank signal toggling: OK Latch signal: OK Data coming out of shift registers: OK Voltages: OK LEDs turned on: NAK Eventually I tested the value into the PMOS switches. Hmm, that’s weird. There was a signal on it’s gate, as expected, but source isn’t changing. Did I get the footprint wrong?\nI took off all the PMOS high side drivers on one of the boards, and bridged gate to drain. So effectively the 74 series 595’s were driving the LED high side directly.\nBig Ooof. -______________________-\nCurrent Date 20th Oct\nI had use the wrong footprint on both the r0.1 boards that had an incorrect LED footprint, and then also again on these! And didn’t pick up on it until now. So with less than 2 weeks I may have had just enough time to order new boards with this fixed. But then all 20 of the boards I’d built would be scrap.\nBodge time The temporary fix I’d put in place on the first board wasn’t going to work. The 595’s do not have enough current driving capability to match the current sink drivers. So when more than 3-4 LEDs are lit a single row the brightness really starts to dip, this produces very undesirable effects for the way the display is wired up.\nJust a few rework items how bad can it be?\nThe mosfets are in SOT-883 packages, which is the same size as a 0402 resistor. They have 3 pads underneath.\nAs shown in this datasheet page for an equivalent part.\nNote I did try and find a part with different pinout that would match my PCB. Unfortunately for me manufactures often like to stick to industry standard pinouts, so they can be drop-in replacements for competitors. It doesn’t really make any sense to release a mosfet with a different unique footprint.\nMy issue was that I had swapped G/S, the two smallest pads. My plan to rework these was to rotate the part such that the G/S pads were in correct orientation. Then with a small length of magnet wire connect the, now displaced, drain back to the PCB.\nSo that’s exactly what I did. For every PMOS on the LED panels.\nLet\u0026rsquo;s do some math real quick. 15 PMOS per panel * 20 panels = 300 bodge wires.\nSo that’s why I started using the saying “This project has 300 bodge wires inside”. I’m not sure on exactly how long it took me to complete all the rework, but I did make it through a 60Hr Audio book that week.\nI tried to have a bit of fun and film some rework under a thermal camera. This is a Boson 640, running at 30Hz with the widest lens. You can see a bit of distortion effects from the lens.\nWrapup I worked through each panel in turn, and did in fact manage to have it all completed (and working) before departing to the US on 2nd November. I did get quiet a few interesting questions from friendly folks at security. I think I generally I would describe it as an electronic art project.\nHere is a short video timelapse of the device being disassembled, assembly is the process just in reverse.\nHere is what one of the basic animations looks like.\nOverall I’m very happy with how it turned out, and I got lots of positive feedback on the project at supercon.\nDownloads If you’re feeling adventurous and want to build one of these for yourself I’d love to see it! Alternatively you can just check out the design files.\nHere is a repo with 3d printable files, and hardware designs for PCBs: https://github.com/gregdavill/d20-hardware\nThe proof of concept firmware that’s running on the device was written in rust, and is available here. (currently embedded in a modified atsamd crate that I added DMA support to): https://github.com/gregdavill/atsamd/tree/d20-controller\nGateware for the ice40 is based of the rgb_panel code from Sylvian “tnt” Munant, but with a slightly modified “phy” to support the unique shift register design of my panels: https://github.com/gregdavill/ice40-playground\nFuture work The controller is a big aspect which could be improved. Adding something with wireless connectivity would be great, to be able to sync up patterns and animations with another device.\nThe panels are working great, and r0.3 updates them, so they don’t require the bodges.\nI think a new controller board might include either an ESP32 or ESP32-S2 chip, along with the FPGA. This would provide a nice way to add extra features, while not having to worry about the tight timing on the display side of things.\nMapping of the pixels into a coordinate space would be very useful. I think this probably isn’t actually too difficult, but just requires wrapping my head around matrix multiplications to move the grid of pixels on each face from a 2d plane into position in 3d space around the icosahedron, then each pixels\u0026rsquo; location can be recorded and used in a lookup table fashion to create interesting animations and effects. Charlie and his new favorite toy\nHeading image source: https://twitter.com/amiedoubleD/status/1205888820262121473 (photo by: https://twitter.com/JunesPhD)\n","permalink":"https://gregdavill.com/posts/d20/","summary":"A tennis ball sized, 20 sided, LED clad, regular polyhedron\nIntroduction The major challenge of making a smaller LED cube in my opinion is the LED panels. Commercially available panels are designed for video walls and typically made at 64x64 pixel as a minimum size. This seems to be a good trade off between cost/complexity/light efficiency. On my previous project mini-led-cube I had overcome one of the major hurdles of creating a smaller cube, because I had designed and built my own custom high density* LED panels.","title":"2,400 LED icosahedron (20 sided)"},{"content":"RTL Architecture The original version of the frame grabbing PCB used an iCE40 HX8K FPGA. This turned out to be a little small for the features I wanted to add. I managed to get it to a state where it would capture images from the Boson 320, but everything was hardwired together, and not easy to alter or reuse.\nIn order to improve module reuse and extendability a standard interface should be used. There are a few of these internal bus architectures available. I’ve decided to use wishbone, Mainly because I’ve been able to find existing wishbone modules that perform most of the major functionality of the frame grabber I’m building.\nComponents wb_intercon Maybe the most important component. It is a collection of verilog components (mux, arbiter, upscaler, downscaler) and a python script that automatically generates all the required modules instantiations and wiring based on a simple easily human readable configuration file.\nDocumentation is a little bit lacking for this. I had to do a bit of reverse engineering on the python parser to understand the format required of the configuration file. For convenience of anyone else wanting to use this component here is a short description. There are two main configuration types, {master, slave} the master needs to know which slaves it will be connected to. The slaves need a base memory address and a length.\n(Some care needs to be taken to ensure that memory segments do not overlap between slaves)\nA python script takes this config file and creates two files a Verilog file and a Verilog header. This script pre-wires in muxes and arbiters as required if two masters have requested to have access over the same slave.\n[master cpu0] slaves = ram0 [slave ram0] offset=0x00000000 size=0x4000 wb_streamer The streamer translates between a stream interface and wishbone transactions. It supports configurable burst length. The stream interface is extendable to support the data from the camera directly. Which is essentially a parallel stream. Combined with some glue logic and other stream utilities (stream_upsizer, stream_dc_fifo) this makes up the main logic to capture the camera data into RAM.\npicoSoC PicoSoC is a small wrapper around picorv32, a small and robust implementation of the RISCV open source CPU architecture. The wrapper includes a SPI driver to read instruction from a SPI FLASH (typically shared with config memory). A simple UART diver, and an optional wishbone / AXI wrapper. Since the rest of my system is using the wishbone wrapper I am using the wishbone wrapper. Note this CPU does not have the greatest IPC values, so it’s more targeted as a data-path controller for there higher performance logic in your system.\nSD controller (sdc) This is a complete 1/4bit open source SD controller. It includes a wishbone configuration interface, and a wishbone master to read/write data blocks. The inclusion of the wishbone master is essentially a dedicated DMA.\nAlthough it’s a complete package I did have to hack around a bit to get it working successfully. I’ll write a more detailed explanation of the changes at some point. But here are the main points.\nBuggy asynchronous FIFO implementation. Results in occasional buggy data in my testing. If sd_clk \u0026laquo; wbclk then the original writers may not have seen this behavior. Currently I fix this by registering the next word of data. Ideally you would replace the FIFO implementation.\nNo example of how to wire into a system. It’s essential to output DATA and CMD signals at the negative edge, to ensure that setup/hold timing is satisfied on the SD cards Internal receivers. This is because data is latched on the rising edge. Registering on the neg-edge inside the I/O block is working for me.\nNo sw-driver. I’ve written my own. (work in progress) See my implementation into FatFs here. It is based of the FatFs example targeting a micro controller with real SD hardware (not SPI mode)\nThis full SD controller is a huge improvement of the SPI based design I was using on the old hardware. But there are still many small areas to tweak in order to boost performance.\nHyperRAM My hyperRAM implementation is based off BML’s great work! I’ve used his PLL example for the Xillinx 7-series. I had to slightly modify timings for working with the DDR modules inside the Lattice ECP5. I’ve also written a basic wrapper and changed the burst read method. This supports wishbone linear bursts assuming that the master issues a request the cycle after an ACK. This is the case for the wb_streamer components, but not achievable with picosoc.\nI’ve hit a few issues with timing on the hyperRAM bus. For awhile it was working perfectly in hardware but the simulator was failing. If I adjusted the code to work on the simulator then the hardware would fail. I think I have tracked this down after drawing out a diagram of the signal timings.\nWhen reading data from the HyperRAM the signals operate in “Aligned” fashion. But there is a delay of up to 5.5ns in the output of this data from the previous clock edge. I was attempting to sample this signal with Sys_clk which edges should be 5.2ns BEFORE the HyperBus clock. This also explains why my simulation was failing.\nCMOS Capture Controller (ccc) This is a module that I have written. It consists of a set of wishbone registers, and logic that operates with the Camera Clock. The main function of this module is to support gating the data stream using v-sync to support capturing a complete frame. Due to its position in the design I have started to add new features into this module, including clocks_per_frame, pixels_per_frame, total_frames_seen.\npixels_per_frame enables the hardware to automatically determine which model of camera is connected a 320 or 640 model.\nCurrent ECP5 Logic usage With all the modules mentioned above I am just over the 12K LUT usage of the ECP5. This is about half of the total available resources. So I think I made a good choice using the ECP5-25F instead of the slightly cheaper ECP5-12F*\nUpdate:\n*The ECP5 is actually contains 25k LUTs inside, there is no 12k die. When making use of the Yosys/NextPnR all 25k LUTs are available\n","permalink":"https://gregdavill.com/posts/boson-frame-grabber-pt5/","summary":"RTL Architecture The original version of the frame grabbing PCB used an iCE40 HX8K FPGA. This turned out to be a little small for the features I wanted to add. I managed to get it to a state where it would capture images from the Boson 320, but everything was hardwired together, and not easy to alter or reuse.\nIn order to improve module reuse and extendability a standard interface should be used.","title":"Boson Frame Grabber Part 5"},{"content":"The new hardware for the Boson Frame Grabber will be based around the Lattice ECP5 family. Lattice make available a free IDE for this FPGA assuming you are not using a model with embedded SERDES. Since we are not, it\u0026rsquo;s perfect for our application.\nThe ECP5 is classified as a high-performance low power FPGA. there are variants available with 2.5/5Gb/s SERDES. The biggest feature for this application is it is available in a 8x8mm 285pin csBGA package. Additionally, the ECP5 is available in 12K,25K,45K,85K LUT variants. Given that my last design was approaching 8K LUTs, I suspect a design will fit in 12K. But the minimal price increase for the 25K variant makes it a pretty good choice.\nDesign The design PCB layout of this new version is derived from the v1_01. With the following changes:\nSwitched out the iCE40HX for an ECP5 in csBGA 285 package. Changed the LDOs. Now separate tiny LDOs for each 1.1, 1.8, 2.5v supplies. The HyperRAM, FLASH, IO level-shifters, JTAG points, Oscillator are all the same. I\u0026rsquo;m still using the altered footprint for the Boson connector, this definitely helps with routing. The extra width from the ECP5 and the extra pins along the top also help with routing the 16bit parallel bus from the camera into the FPGA.\nYou can see the updated FPGA page of the schematic below. I\u0026rsquo;m using around 60 out of the 118 available PIO pins on this package. I tried to constrain high-speed buses like the SD card and HyperRAM to their own bank. But I don\u0026rsquo;t think that\u0026rsquo;s particularly important at the speeds I\u0026rsquo;m working within this design. What is important is ensuring that devices connected to a particular bank are at the right IOVDD level.\nWe have 2 different IO voltages in this design\n1.8V - HyperRAM, Boson, Oscillator, I/O 3.3V - SDMMC, FLASH Because I had specifically used level-shifting Tri-stateable Buffers for the two external IO ports, I\u0026rsquo;m easily able to control them from a 1.8V IO bank.\nThe main reason for using these buffers is to ensure that the low voltage sensitive IO pins of the FPGA are somewhat protected from external signals, The buffers used are SN74LVC1T45\u0026rsquo;s They will tolerate voltages up to 7V and retain their high-impedance state even when they are not powered.\nWith these Tri-stable buffers, it\u0026rsquo;s often useful to write on your schematic what the DIR pin actually does. Often they can take an inverted input. Writing this stuff on a schematic it is a lot easier to see than pulling up the datasheet again if you forget or want to double check.\nI\u0026rsquo;ll mention the LDOs I used again. I used TLV733P parts, but it\u0026rsquo;s a jelly bean part available from many different manufacturers. The package I need is the XSON style 1x1mm package, very challenging to solder. But the small size is essential to fitting everything on my 21x21mm PCB. For reference, the capacitors next the regulators between are 0402!! Yes, they\u0026rsquo;re small. I\u0026rsquo;ve seen raw sugar crystals bigger than these regulators. Check Leadtimes (I designed a v1_03 PCB) One thing I did not check until after I had ordered wy PCBs was the availability of the ECP5 in csBGA 285 package. It turns out there was either a bit of a shortage, or it\u0026rsquo;s not a standard stocking part. Lattice lists an 8 week lead time, luckily from lattice you can buy singles with this lead time for prototypes. But from some distributors request you order an entire tray or 168 parts!\nBecause I was impatient, I decided to create a testing board using an in-stock package of the part. Here is that board. I made it bigger to support an LCD screen.\nThis board is v1_03 in the github project. But it has an errata list longer than my arm. All caused by rushing the design over one weekend. I managed to get it mostly working, but it will never support auto-configuration from FLASH. So in order to run it, you are required to load a bitstream through JTAG.\nWhat ended up happening is that the day I assembled this prototype big-board, I found that Lattice had stock of one variant of the ECP in csBGA 285 package. This ended up being around 2 weeks out of the quoted 8 weeks lead time.\nv1_02 (But this time with parts) With parts in hand, the assembly proceeded without a hitch. I made use of a stencil from OSH Stencils. This is the first time I\u0026rsquo;ve attempted this. But I added holes to my edge rails on my PCB panel, and spec\u0026rsquo;d corresponding holes in the stencil. Using some small Steel pins makes stencil alignment PERFECT!\nWhen I designed the iCE40 Version I thought I had packed the PCB, but this is even denser. I\u0026rsquo;m very proud of my efforts to design this board and still remain within a \u0026ldquo;standard\u0026rdquo; PCB 4 layer process.\nI am still hand-assembling the rear-side components. Just use lots of flux, and a fine tipped iron with a flat edge. Lastly, a family shot of v1_01 next to its superior v1_02 hardware.\nIn the next part I\u0026rsquo;ll finally describe the firmware* design. Hopefully, I can this hardware to work. (Even if doesn\u0026rsquo;t work, it looks great!)\n(*Is Verilog firmware? That\u0026rsquo;s something I\u0026rsquo;m not clear about.)\nUpdate:\nI\u0026rsquo;ve been informed that RTL is often referred to as \u0026ldquo;Gateware\u0026rdquo;. Which seems quite fitting\n","permalink":"https://gregdavill.com/posts/boson-frame-grabber-pt4/","summary":"\u003cp\u003eThe new hardware for the Boson Frame Grabber will be based around the Lattice ECP5 family. Lattice make available a free IDE for this FPGA assuming you are not using a model with embedded SERDES. Since we are not, it\u0026rsquo;s perfect for our application.\u003c/p\u003e","title":"Boson Frame Grabber Part 4"},{"content":"In this part I want to talk about the firmware, or code, this device will need in order to operate as I want.\nBut before I get to that lets take a quick step backwards to some back of the envelope engineering I did when I was thinking about the hardware required to save an image from the camera.\nData Flow The Boson is designed to stream images out automatically, the camera has a control interface, but you cannot simply ask it to \u0026ldquo;snap\u0026rdquo; a photo, and read it out byte by byte. Instead it just rudely spews out data. It has a 16bit bus running with a 13.5MHz pixel clock. This equates to a bus speed of 27MByte/s. Luckily for us pixel data on this bus comes in bursts, before and after each line of valid data there is a gap and after every line in a frame has been transmitted there is a few lines blank. These are Horizontal and vertical blanking periods designed to give electronics some time to process the information. (My understanding is that originally these were to give CRT screens time to energize coils and steer the electron beam back to be ready for the start of the next row. But they are still common place in many video formats.)\nI decided to add high speed RAM to the design in order to ensure I could reliably capture the video frame. I have used SD cards in the past and it is pretty common place for them to have variable delays when writing data blocks to them as they perform various internal operations. If I could get away with bypassing the RAM in the final design, great, but I still wanted it in the hardware.\nOne benefit of using the RAM is that it doesn\u0026rsquo;t matter what speed the SD card is running at – this makes life easier. I can develop the modules that are needed to run the system then leave as much optimization till the end.\nVerilog \u0026amp; PicoSoC Code that describes hardware. As mentioned this is my first FPGA project. I had already selected the iCE40HX8K as it was the largest ICE40 in the smallest package. This particular FPGA has 8k LUTs. I didn\u0026rsquo;t know how many LUTs my design would require. Is 8k a lot? What is a LUT? I\u0026rsquo;m not going to go into FPGA basics, but from my experience 8k is enough to implement a RISCV 32 bit processor and a handful of basic peripherals. It is enough to get your feet wet in a real FPGA project!\nI had chosen the ICE40 as a target device because I was reading about a free open source FPGA tool-chain ice-storm. I followed the guides and examples and got a LED blinking on the back of my board! This project was on it\u0026rsquo;s feet. But I was still a bit outside my comfort zone.\nClaire Xen is the creator of the icestorm project. She also created a lightweight RISCV processor called picorv32. More importantly for me (A verilog newbie) she packaged this into PicoSoC.\nPicoSoC is a combination of the RISCV CPU picorv32, a flash memory controller for reading in program data, some SRAM, and a UART serial port. Also an example built on the Lattice HX8K evaluation board! The processor let you write C code and using memory mapped register directly control and monitor bits in your custom hardware. it was a perfect way for me to ease into FPGA design. PicoSoC has some great step by step instructions in order to compile and get it loaded, one of the steps is downloading and compiling a RISCV variant of GCC. This went smoothly but was the slowest port (~4 hours on my slow laptop.) The wait was worth it, because after it finished I had PicoSoC loaded and running on my custom hardware. The UART link to the PC gives you a very simple text console which I think is perfect for adding to and modifying in firmware. (Love the PicoSoC splash screen btw Clifford!)\nThink Modular Verilog is constructed as a very hierarchical language. Which means when developing systems for FPGAs you should be thinking about modules, how can you split your design into modular blocks that fit together. I envisioned a system as shown above, I had now validated that the FPGA was functioning, SPI FLASH and programming worked, and my User I/O and LED worked. I wanted to write some logic to test the SD card, HyperRAM, and Boson Interface. Any of these could have a hardware bug in the PCB design that could render this prototype useless.\nBoson IF I wrote the Boson Interface first as a basic FIFO, using commands in the SoC\u0026rsquo;s firmware I was able to reset the FIFO and print out 16 values that had appeared from the camera over serial. This with a combination of holding my hand in front of the camera indicated that data was been read correctly from the camera.\nHyperRAM I had started working on a hyperRAM module with my first prototype hardware. However I didn\u0026rsquo;t really understand what interfaces I would need to support the burst style data that the RAM needs in order to sustain it\u0026rsquo;s read speeds. At this time I saw Kevin Hubbard from Black Mesa labs had just released an open source HyperRAM library, His library relies on dividing the clock rate by 4 to properly generate the DDR signal timings without having to worry about device specific PLLs. With a bit of reading though his very well documented code I was able to add his module to the PicoSoC system bus and test the RAM using some simple functions in C.\nMicro SD \u0026amp; FAT The biggest benefit of using a softcore processor in my design in my opinion was the ability to leverage existing open source software projects. FatFs is one of those projects, I\u0026rsquo;ve used it on countless projects in the past. The example projects include a \u0026ldquo;barebones\u0026rdquo; implementation of the low level control using bit-banged IO. In order to get this to work I just had to extend the GPIO registers from write only to R/W and map them to the SD card pinout in verilog. With those small changes* I was able to write a file to the SD card!\nI spent an entire evening scratching my head as to why FatFs wasn\u0026rsquo;t working. As soon as I looked at the memory-map output from GCC I worked out why, I think one of the goals of PicoSoC is to be simple enough to get up and running fast. Because of this the example firmware (what my code was based off) only utilized the RAM on the stack, the linker never declared where to store static/global variables, and the startup code never initialized these. I did a few unspeakable linker-hacks to get it to work initally. A better solution is to use the code provided by Miodrag Milanović, Who did a great job porting microPython to the picoSoC.\nPick Your Battles Now with each hardware component tested to be working I knew the hardware should be capable of capturing an image from the camera, I just had to tell it how to do it.\nMy idea for a simple capture sequence is as follows:\nOn powerup Boson IF module has control over the HyperRAM. The CPU tries to access the HyperRAM and becomes stalled. The Boson IF waits for a Vsync pulse to synchronize with the image. It captures an image through a Dual-clock FIFO. (Boson Camera Controls the pixel clock) A small state-machine empties the FIFO. After 3202562 bytes the state-machine in Boson IF releases the HyperRAM. CPU takes over and using FatFS writes an image to the SD card. To my surprise this worked! Not ideal though, you had to restart the camera to take a new photo, the SD card was still slow, and it would over-write the last photo you took.\nYou can see a few errors with this photo, firstly I miss-judged what the focal distance would see. There is a 2 pixel band on the left image that\u0026rsquo;s actually pixels from start of the next line. I messed up the endian-ness so every pair of pixels is flipped. Still a success!! Optimise When Ready I systematically went through and added performance to each module.\nHyperRAM got updated to make use of the DDR IO and PLL in the ICE40. SD driver got updated to a hardware SPI module running at 12MHz. Control registers added to the Boson IF to enable capture through the picoSoC terminal. Lastly I added a simple DMA to copy data from the HyperRAM out into the SD card without requiring the CPU. This greatly improved performance. I reduced the time to save an 320x256 image from ~12s to ~0.3s.\nMoving Forward At this point I\u0026rsquo;ve run out of space inside the ICE40HX8K. I\u0026rsquo;m sure there is room to optimise the current design, but it is very difficult to add extra features. In order to push the performance even further I will need to swap the SD SPI driver for a real SD 4-bit interface. There are a few open source versions but none of them fit. Time to look for a bigger FPGA?\nUp to this point I had I had been working with a Boson 320x256 9Hz I\u0026rsquo;ve borrowed from work. GroupGets a FLIR distributor among other things offered to send me a Boson 640x512 60Hz model! Amazing! If you\u0026rsquo;re interested in picking up a Boson Camera check out their range!\nUnfortunately the Camera running at 60Hz outputs data too fast for the logic in my HX8K board to keep up with. It\u0026rsquo;s pixel clock is 27MHz at 60Hz which corresponds to a 54MByte/s bus speed. The FIFO can capture this but my HyperRAM bus is not able to sustain a data rate to be ready by the next line. But by enabling the average in the camera the frame rate is reduced to 30Hz and the clock brought down to 13.5MHz, with some small tweaks I was able to capture this frame. (95 degree FOV is VERY wide!)\nI have plans to create an updated version featuring a more power processor capable of handling both the Boson 320 and Boson 640. Stay tuned for more details about this in Part 4!\nHere is a teaser! 😉\n","permalink":"https://gregdavill.com/posts/boson-frame-grabber-pt3/","summary":"\u003cp\u003eIn this part I want to talk about the firmware, or code, this device will need in order to operate as I want.\u003c/p\u003e","title":"Boson Frame Grabber Part 3"},{"content":"In part 1, I discussed the version 1 prototype I had built. Just after ordering the PCBs for that project I decided to start thinking about miniaturizing the hardware.\nIf I could integrate more parts into the FPGA I could reduce the BOM and PCB area required for the entire device. I was still looking at the iCE40 family and discovered the iCE40HX8K came in a 0.5mm BGA 8x8mm. This was small enough to fit directly behind the camera core!! (Notice the pocket on the back of the camera casting, it\u0026rsquo;s just over 1mm deep)\nDesign The design revolves around the two main ICs, the FPGA, and the HyperRAM. These were placed on the PCB behind the camera. The connector for the camera with the same custom footprint enabled all the camera signals to be routed out on a single layer, the use of an FPGA also helped here, as most of the time you can simply swap pins to help with routing.\nThe FPGA is now responsible for handling the SD logic, I routed the signals required for 4bit SD mode, this can also be used in SPI mode by the FPGA. Starting with SPI mode should make this easier to bring up the firmware.\nThe device features 2 user I/O. these run through a bidirectional level converter, and TVS. My thoughts here is that this will make the I/O much more robust as the level converters I\u0026rsquo;m using will easily handle input voltages of 6-7V without complaint, the same can not be said for the FPGA.\nThe RAM used here is the same HyperRAM as v1 prototype. 64Mbit DRAM with a 12pin HyperBus interface. I used a tiny 8Mbit QSPI Flash in 8 pin 2x3 USON package. and a JTAG interface on the back of the device which makes use of pogopins.\nFT232H programmer I was going to have to develop my own programmer, fortunately Piotr had already built this great FT232H multitool! I was able to use his design and simply create my own adapter PCB!\nHardware PCBs arrived from OSHPark. I haven\u0026rsquo;t used OSHPark for PCBs since it was Laen\u0026rsquo;s group PCB. (and the boards were still blue. :S ). But they are great quality, which should be expected. I ordered both the FT232H multitool design, a pogopin breakout, and my new Boson Frame Grabber PCB.\nI had ordered a PCB from OSHPark before I discovered the hyperRAM footprint error on my last PCB, so unfortunately the main PCB was useless (what are you gonna do). I was able to use the programmer, and I used the PCB for BGA practice! (I shorted a few pins on this attempt, so well worth it). Speaking of OSHPark PCBs damn do they look nice! That LPI silkscreen process really shines!\nHardware Take 2 I had already ordered some new PCBs from JLCPCB.com after correcting the footprint of the HyperRAM. These boards showed up within about a week of ordering, this is of course using DHL (Otherwise your PCBs typically spend a few weeks in the mail system).\nThe PCBs from JLCPCB look great! this was the first time I used their service. Their manufacturing specs are very impressive for the price! I\u0026rsquo;ll definitely be using their service again! Although this is only a prototype run, given the size of my PCBs I decided to create a small panel using the GerberPanelizer tool (http://blog.thisisnotrocketscience.nl/projects/pcb-panelizer/)\nThis worked out great! JLCPCB did not have any issue routing out the space between boards. (I kept around 2mm between PCBs.)\nI soldered up a single PCB by hand, this is time consuming, but forces you to relax. (If you\u0026rsquo;re not relaxed while placing small parts with tweezers they tend to fling out and shoot across the room :S ). Again hot-air and flux. You can never have too much flux, I use AMTECH NC-559-V2-TF that I buy in large 30cc tubes that you can pickup from Louis Rossmann.\nAfter assembly I really didn\u0026rsquo;t expect it to work, this is the first time I\u0026rsquo;ve soldered a 0.5mm BGA by hand, and you can\u0026rsquo;t be sure that it\u0026rsquo;s correctly soldered unless you use expensive x-ray inspection tools, or destructive methods (that would destroy your prototype). I connected up my homemade programmer and powered on the board with 3.3V from my bench power supply. It worked!\nA little verilog code later, tinkering with examples found online I managed to have a compiled bitstream that would flash a LED. The LED started flashing. ^_^\nThe LED blinks? Now what?\nPart 3 will take a look a the verilog and firmware required to get this thing up and running. Check it out here\n","permalink":"https://gregdavill.com/posts/boson-frame-grabber-pt2/","summary":"\u003cp\u003eIn part 1, I discussed the version 1 prototype I had built. Just after ordering the PCBs for that project I decided to start thinking about miniaturizing the hardware.\u003c/p\u003e","title":"Boson Frame Grabber Part 2"},{"content":"Background FLIR has recently released a new OEM thermal Camera core. The Boson. These cores are self contained units that handle all the complexities of thermal imaging. They contain the thermal image sensor itself, a NUC/FFC shutter, and a lens assembly capable of focusing thermal energy. They also contain control electronics that present a standard CMOS style image sensor parallel interface. (DATA + CLK + HSYNC/VSYNC).\nHaving used the previous Thermal core from FLIR (The Tau 2) at work in project, our local distributor sent us some Boson cores to have around for integration. These unfortunately sat on our shelf for a few months. I wanted to learn how to design projects with FPGAs, so I decided to create an FPGA based product to capture the data stream from the Boson core into a usable format.\nDesign Prototype v1 This is my very first FPGA project, I had used FPGAs before in a uni class on Digital Electronics. I had also learnt about the RISCV CPU architecture in Computer Architecture. But had never designed an FPGA into a project. I had just listened to an episode of the Amp Hour with Clifford Wolf, explaining the Lattice iCE40 open source toolchain: icestorm. So naturally I started there. (Also Naturally I picked the only variant in the iCE40 family that is not compatible with icestom. Still supported by lattices\u0026rsquo; tools.)\nI crawled through the datasheets for the iCE40 Family and the variant I picked the iCE5LP4K, this was available in an easy to solder QFN 48. I decided to \u0026ldquo;simplify\u0026rdquo; the FPGA work by basically creating a large FIFO. This would capture a frame from the high speed datastream of the camera into some external RAM, then a microcontroller could read this data at its own pace and save it to an SD card. This probably would have worked, but I never developed the code for this completely. I had already started developing v2 with a larger FPGA on a smaller PCB. That will be talked about in part 2.\nThe RAM I chose was 64Mbit of hyperRAM. HyperRAM is self refreshing DRAM, which is refered to as Pseudo SRAM (PSRAM). This provides the high density benefits of DRAM with the simplicity of SRAM. It uses a 12 wire Interface bus which uses a 8bit DDR data bus and control signals. Due to its nature it\u0026rsquo;s a champ at long bursts of data. Perfect for the streamed data from the camera.\nI chose the SAMD51 as a microcontroller to handle the SD + FAT stuff mostly because I had just used them in another project. :) But they do feature a true SDMMC 4 bit interface which is essential to get any decent performance from an SD card.\nHardware Assembly This is the part of a project I enjoy the most. I was able to hand assemble this prototype with a soldering iron and a hot air setup. (Tip: use lots of flux). The PCBs arrived from PCBWay, I had all my parts from Mouser/Digikey, I was ready to assemble.\nSome comically small parts on this board are these voltage regulators, They are adjustable dual LDOs, I used 0603 caps/resistors which individually are almost larger than the chip. Still an easy job to assemble with the right tools and some practice.\nOne interesting point of this prototype was the discovery I could make a custom footprint for the connector in KiCad, this custom version removes alot of pins that are unused in this application. This enables me to route out the signals all on the top layer. Because these pins may still have a voltage/signal present on them it is essential that a soldermask is present underneath the repurposed pins.\nFirmware I designed the FPGA to be configured through a slave device of the samd51. This took too long to get working, by the time I had it working and had started working on the verilog the new prototype had arrived, and I decide to leave this project. It had served as a great first step in getting started with FPGAs and had given me added confidence with the tools and workflow.\nHowever I did develop a simple hyperRAM interface in a verilog simulator, when I tried it on the real hardware I discovered a serious bug\u0026hellip;\nErrata In my haste to develop an entire PCB with new components. I had mislabelled the coordinates on the BGA footprint. This required me to perform the following rework. Surprisingly this does actually work. My code that tested this was only running at 12MHz bus speed. But I\u0026rsquo;m still impressed with my own job. I did this without the aid of a microscope (I have since bought a microscope.)\nIn Part 2 I take a look at the hardware behind version 2 prototype!\n","permalink":"https://gregdavill.com/posts/boson-frame-grabber-pt1/","summary":"Background FLIR has recently released a new OEM thermal Camera core. The Boson. These cores are self contained units that handle all the complexities of thermal imaging. They contain the thermal image sensor itself, a NUC/FFC shutter, and a lens assembly capable of focusing thermal energy. They also contain control electronics that present a standard CMOS style image sensor parallel interface. (DATA + CLK + HSYNC/VSYNC).\nHaving used the previous Thermal core from FLIR (The Tau 2) at work in project, our local distributor sent us some Boson cores to have around for integration.","title":"Boson Frame Grabber Part 1"}]